{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54206d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "# Define the paths to the image and label files\n",
    "IMG_PATH = \"E:/mtech/secondsem/CV_Lab/Project/Hands\" #whole images\n",
    "LABEL_PATH = \"E:/mtech/secondsem/CV_Lab/Project/HandInfo.csv\" #information of images\n",
    "# Load the label data from the CSV file\n",
    "labels_df = pd.read_csv(LABEL_PATH)\n",
    "labels_dict = {}\n",
    "\n",
    "# Iterate over the rows of the CSV file and extract the labels for each image\n",
    "for index, row in labels_df.iterrows():\n",
    "    filename = row['imageName']\n",
    "    label = row['aspectOfHand']\n",
    "    labels_dict[filename] = label\n",
    "\n",
    "# Load the images and labels into memory\n",
    "images = []\n",
    "labels = []\n",
    "for filename in os.listdir(IMG_PATH):\n",
    "    img = cv2.imread(os.path.join(IMG_PATH, filename))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    images.append(img)\n",
    "    labels.append(labels_dict[filename])\n",
    "\n",
    "# Convert the data to numpy arrays\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Print the shape of the data arrays\n",
    "print(\"Images shape:\", images.shape)\n",
    "print(\"Labels shape:\", labels.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a5995c",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9f6fb57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "277/277 [==============================] - 178s 620ms/step - loss: 0.6664 - accuracy: 0.6291 - val_loss: 0.6537 - val_accuracy: 0.6462\n",
      "Epoch 2/10\n",
      "277/277 [==============================] - 166s 600ms/step - loss: 0.6575 - accuracy: 0.6407 - val_loss: 0.6532 - val_accuracy: 0.6462\n",
      "Epoch 3/10\n",
      "277/277 [==============================] - 164s 593ms/step - loss: 0.6566 - accuracy: 0.6407 - val_loss: 0.6509 - val_accuracy: 0.6462\n",
      "Epoch 4/10\n",
      "277/277 [==============================] - 149s 539ms/step - loss: 0.6554 - accuracy: 0.6407 - val_loss: 0.6498 - val_accuracy: 0.6462\n",
      "Epoch 5/10\n",
      "277/277 [==============================] - 148s 534ms/step - loss: 0.6558 - accuracy: 0.6407 - val_loss: 0.6522 - val_accuracy: 0.6462\n",
      "Epoch 6/10\n",
      "277/277 [==============================] - 152s 549ms/step - loss: 0.6552 - accuracy: 0.6407 - val_loss: 0.6507 - val_accuracy: 0.6462\n",
      "Epoch 7/10\n",
      "277/277 [==============================] - 150s 543ms/step - loss: 0.6553 - accuracy: 0.6407 - val_loss: 0.6512 - val_accuracy: 0.6462\n",
      "Epoch 8/10\n",
      "277/277 [==============================] - 159s 576ms/step - loss: 0.6545 - accuracy: 0.6407 - val_loss: 0.6508 - val_accuracy: 0.6462\n",
      "Epoch 9/10\n",
      "277/277 [==============================] - 145s 525ms/step - loss: 0.6550 - accuracy: 0.6407 - val_loss: 0.6500 - val_accuracy: 0.6462\n",
      "Epoch 10/10\n",
      "277/277 [==============================] - 135s 488ms/step - loss: 0.6536 - accuracy: 0.6407 - val_loss: 0.6498 - val_accuracy: 0.6462\n",
      "70/70 [==============================] - 16s 226ms/step - loss: 0.6498 - accuracy: 0.6462\n",
      "Test loss: 0.64975905418396\n",
      "Test accuracy: 0.6462093591690063\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Define the paths to the image and label files\n",
    "IMG_PATH = \"E:/mtech/secondsem/CV_Lab/Project/Hands/Hands\" #whole images\n",
    "LABELS_PATH = \"E:/mtech/secondsem/CV_Lab/Project/HandInfo.csv\"\n",
    "\n",
    "# Load the labels\n",
    "labels_df = pd.read_csv(LABELS_PATH)\n",
    "\n",
    "# Define the patch size\n",
    "PATCH_SIZE = 32\n",
    "\n",
    "# Define a list to store the image patches\n",
    "image_patches = []\n",
    "\n",
    "# Load and preprocess each image\n",
    "for i, row in labels_df.iterrows():\n",
    "    img_path = os.path.join(IMG_PATH, row[\"imageName\"])\n",
    "    img = Image.open(img_path)\n",
    "    img = img.resize((224, 224)) # ResNet50 model takes input size of (224,224)\n",
    "    \n",
    "    # Divide the image into patches\n",
    "    for j in range(0, img.size[0], PATCH_SIZE):\n",
    "        for k in range(0, img.size[1], PATCH_SIZE):\n",
    "            patch = img.crop((j, k, j+PATCH_SIZE, k+PATCH_SIZE))\n",
    "            patch_array = np.array(patch)\n",
    "            image_patches.append(patch_array)\n",
    "\n",
    "# Convert the list of image patches to a numpy array\n",
    "image_patches = np.array(image_patches)\n",
    "\n",
    "# Reshape the image patches into sequences of vectors\n",
    "seq_length = image_patches.shape[0] // labels_df.shape[0]\n",
    "image_seqs = image_patches.reshape((-1, seq_length, PATCH_SIZE*PATCH_SIZE*3))\n",
    "\n",
    "# Extract the labels and convert to one-hot encoding\n",
    "labels = labels_df[\"gender\"].values\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(labels)\n",
    "labels = encoder.transform(labels)\n",
    "labels = to_categorical(labels, num_classes=2)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(image_seqs, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(seq_length, PATCH_SIZE*PATCH_SIZE*3)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_images, train_labels, epochs=10, batch_size=32, validation_data=(test_images, test_labels))\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(\"Test loss:\", test_loss)\n",
    "print(\"Test accuracy:\", test_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ddf707",
   "metadata": {},
   "source": [
    "# VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf049096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "277/277 [==============================] - 108s 381ms/step - loss: 2.5808 - accuracy: 0.6755 - val_loss: 0.7092 - val_accuracy: 0.5776\n",
      "Epoch 2/10\n",
      "277/277 [==============================] - 108s 391ms/step - loss: 0.4421 - accuracy: 0.8074 - val_loss: 0.3656 - val_accuracy: 0.8416\n",
      "Epoch 3/10\n",
      "277/277 [==============================] - 107s 387ms/step - loss: 0.2999 - accuracy: 0.8761 - val_loss: 0.3885 - val_accuracy: 0.8132\n",
      "Epoch 4/10\n",
      "277/277 [==============================] - 106s 382ms/step - loss: 0.2544 - accuracy: 0.8985 - val_loss: 0.2091 - val_accuracy: 0.9039\n",
      "Epoch 5/10\n",
      "277/277 [==============================] - 112s 404ms/step - loss: 0.2303 - accuracy: 0.9168 - val_loss: 0.1462 - val_accuracy: 0.9377\n",
      "Epoch 6/10\n",
      "277/277 [==============================] - 114s 412ms/step - loss: 0.1780 - accuracy: 0.9327 - val_loss: 0.1702 - val_accuracy: 0.9296\n",
      "Epoch 7/10\n",
      "277/277 [==============================] - 112s 405ms/step - loss: 0.1526 - accuracy: 0.9416 - val_loss: 0.1116 - val_accuracy: 0.9562\n",
      "Epoch 8/10\n",
      "277/277 [==============================] - 102s 368ms/step - loss: 0.1316 - accuracy: 0.9500 - val_loss: 0.0905 - val_accuracy: 0.9684\n",
      "Epoch 9/10\n",
      "277/277 [==============================] - 105s 380ms/step - loss: 0.1208 - accuracy: 0.9558 - val_loss: 0.1002 - val_accuracy: 0.9625\n",
      "Epoch 10/10\n",
      "277/277 [==============================] - 117s 424ms/step - loss: 0.1152 - accuracy: 0.9637 - val_loss: 0.1477 - val_accuracy: 0.9486\n",
      "70/70 [==============================] - 10s 136ms/step - loss: 0.1477 - accuracy: 0.9486\n",
      "Test loss: 0.14774516224861145\n",
      "Test accuracy: 0.9485559463500977\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Define the paths to the image and label files\n",
    "IMG_PATH = \"E:/mtech/secondsem/CV_Lab/Project/Hands/Hands\" #whole images\n",
    "LABELS_PATH = \"E:/mtech/secondsem/CV_Lab/Project/HandInfo.csv\"\n",
    "\n",
    "# Load the labels\n",
    "labels_df = pd.read_csv(LABELS_PATH)\n",
    "\n",
    "# Define a list to store the images\n",
    "images = []\n",
    "\n",
    "# Load and preprocess each image\n",
    "for i, row in labels_df.iterrows():\n",
    "    img_path = os.path.join(IMG_PATH, row[\"imageName\"])\n",
    "    img = Image.open(img_path)\n",
    "    img = img.resize((64, 64))\n",
    "    img_array = np.array(img)\n",
    "    images.append(img_array)\n",
    "\n",
    "# Convert the list of images to a numpy array\n",
    "images = np.array(images)\n",
    "\n",
    "# Extract the labels and convert to one-hot encoding\n",
    "labels = labels_df[\"gender\"].values\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(labels)\n",
    "labels = encoder.transform(labels)\n",
    "labels = to_categorical(labels, num_classes=2)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Define the model architecture\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_images, train_labels, epochs=10, batch_size=32, validation_data=(test_images, test_labels))\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(\"Test loss:\", test_loss)\n",
    "print(\"Test accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5bf64e",
   "metadata": {},
   "source": [
    "# Resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31b9cd78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "277/277 [==============================] - 3965s 14s/step - loss: 3.6577 - accuracy: 0.8692 - val_loss: 0.2220 - val_accuracy: 0.9725\n",
      "Epoch 2/10\n",
      "277/277 [==============================] - 3898s 14s/step - loss: 0.5698 - accuracy: 0.9498 - val_loss: 0.0825 - val_accuracy: 0.9851\n",
      "Epoch 3/10\n",
      "277/277 [==============================] - 3950s 14s/step - loss: 0.2453 - accuracy: 0.9690 - val_loss: 0.0658 - val_accuracy: 0.9883\n",
      "Epoch 4/10\n",
      "277/277 [==============================] - 3957s 14s/step - loss: 0.1232 - accuracy: 0.9772 - val_loss: 0.0345 - val_accuracy: 0.9919\n",
      "Epoch 5/10\n",
      "277/277 [==============================] - 3927s 14s/step - loss: 0.0627 - accuracy: 0.9857 - val_loss: 0.0760 - val_accuracy: 0.9707\n",
      "Epoch 6/10\n",
      "277/277 [==============================] - 3895s 14s/step - loss: 0.0511 - accuracy: 0.9897 - val_loss: 0.0342 - val_accuracy: 0.9896\n",
      "Epoch 7/10\n",
      "277/277 [==============================] - 3882s 14s/step - loss: 0.0309 - accuracy: 0.9928 - val_loss: 0.0126 - val_accuracy: 0.9964\n",
      "Epoch 8/10\n",
      "277/277 [==============================] - 3877s 14s/step - loss: 0.0325 - accuracy: 0.9918 - val_loss: 0.0290 - val_accuracy: 0.9901\n",
      "Epoch 9/10\n",
      "277/277 [==============================] - 3597s 13s/step - loss: 0.0162 - accuracy: 0.9959 - val_loss: 0.0123 - val_accuracy: 0.9946\n",
      "Epoch 10/10\n",
      "277/277 [==============================] - 3522s 13s/step - loss: 0.0177 - accuracy: 0.9946 - val_loss: 0.0103 - val_accuracy: 0.9973\n",
      "70/70 [==============================] - 695s 10s/step - loss: 0.0103 - accuracy: 0.9973\n",
      "Test loss: 0.010280001908540726\n",
      "Test accuracy: 0.9972923994064331\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Define the paths to the image and label files\n",
    "IMG_PATH = \"E:/mtech/secondsem/CV_Lab/Project/Hands/Hands\" #whole images\n",
    "LABELS_PATH = \"E:/mtech/secondsem/CV_Lab/Project/HandInfo.csv\"\n",
    "\n",
    "# Load the labels\n",
    "labels_df = pd.read_csv(LABELS_PATH)\n",
    "\n",
    "# Define a list to store the images\n",
    "images = []\n",
    "\n",
    "# Load and preprocess each image\n",
    "for i, row in labels_df.iterrows():\n",
    "    img_path = os.path.join(IMG_PATH, row[\"imageName\"])\n",
    "    img = Image.open(img_path)\n",
    "    img = img.resize((224, 224)) # ResNet50 model takes input size of (224,224)\n",
    "    img_array = np.array(img)\n",
    "    images.append(img_array)\n",
    "\n",
    "# Convert the list of images to a numpy array\n",
    "images = np.array(images)\n",
    "\n",
    "# Extract the labels and convert to one-hot encoding\n",
    "labels = labels_df[\"gender\"].values\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(labels)\n",
    "labels = encoder.transform(labels)\n",
    "labels = to_categorical(labels, num_classes=2)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Load the pre-trained ResNet50 model\n",
    "resnet = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the layers in the pre-trained model\n",
    "for layer in resnet.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add new layers on top of the pre-trained model\n",
    "x = Flatten()(resnet.output)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "predictions = Dense(2, activation='softmax')(x)\n",
    "model = Model(inputs=resnet.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_images, train_labels, epochs=10, batch_size=32, validation_data=(test_images, test_labels))\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(\"Test loss:\", test_loss)\n",
    "print(\"Test accuracy:\", test_acc)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3573a1",
   "metadata": {},
   "source": [
    "# Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b20712ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "277/277 [==============================] - 3093s 11s/step - loss: 0.8356 - accuracy: 0.7869 - val_loss: 0.9180 - val_accuracy: 0.6462\n",
      "Epoch 2/10\n",
      "277/277 [==============================] - 2804s 10s/step - loss: 0.9961 - accuracy: 0.7843 - val_loss: 73.9547 - val_accuracy: 0.6462\n",
      "Epoch 3/10\n",
      "277/277 [==============================] - 2837s 10s/step - loss: 1.1666 - accuracy: 0.7778 - val_loss: 4.9817 - val_accuracy: 0.6462\n",
      "Epoch 4/10\n",
      "277/277 [==============================] - 2842s 10s/step - loss: 0.8602 - accuracy: 0.8010 - val_loss: 9.4120 - val_accuracy: 0.6462\n",
      "Epoch 5/10\n",
      "277/277 [==============================] - 2838s 10s/step - loss: 0.5315 - accuracy: 0.8262 - val_loss: 66.0731 - val_accuracy: 0.6462\n",
      "Epoch 6/10\n",
      "277/277 [==============================] - 2855s 10s/step - loss: 0.6538 - accuracy: 0.8324 - val_loss: 3.1423 - val_accuracy: 0.3547\n",
      "Epoch 7/10\n",
      "277/277 [==============================] - 2897s 10s/step - loss: 1.0278 - accuracy: 0.7669 - val_loss: 3.9196 - val_accuracy: 0.3538\n",
      "Epoch 8/10\n",
      "277/277 [==============================] - 2897s 10s/step - loss: 0.5443 - accuracy: 0.8344 - val_loss: 4.8768 - val_accuracy: 0.6462\n",
      "Epoch 9/10\n",
      "277/277 [==============================] - 2882s 10s/step - loss: 0.4061 - accuracy: 0.8581 - val_loss: 9.9281 - val_accuracy: 0.6462\n",
      "Epoch 10/10\n",
      "277/277 [==============================] - 2844s 10s/step - loss: 0.3680 - accuracy: 0.8705 - val_loss: 109.6738 - val_accuracy: 0.6462\n",
      "70/70 [==============================] - 152s 2s/step - loss: 109.6738 - accuracy: 0.6462\n",
      "Test loss: 109.67379760742188\n",
      "Test accuracy: 0.6462093591690063\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.layers.experimental.preprocessing import RandomFlip, RandomRotation, RandomTranslation, RandomZoom, Rescaling\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Define the paths to the image and label files\n",
    "IMG_PATH = \"E:/mtech/secondsem/CV_Lab/Project/Hands/Hands\" #whole images\n",
    "LABELS_PATH = \"E:/mtech/secondsem/CV_Lab/Project/HandInfo.csv\"\n",
    "\n",
    "# Load the labels\n",
    "labels_df = pd.read_csv(LABELS_PATH)\n",
    "\n",
    "# Define a list to store the images\n",
    "images = []\n",
    "\n",
    "# Load and preprocess each image\n",
    "for i, row in labels_df.iterrows():\n",
    "    img_path = os.path.join(IMG_PATH, row[\"imageName\"])\n",
    "    img = Image.open(img_path)\n",
    "    img = img.resize((224, 224))\n",
    "    img_array = np.array(img)\n",
    "    images.append(img_array)\n",
    "\n",
    "# Convert the list of images to a numpy array\n",
    "images = np.array(images)\n",
    "\n",
    "# Extract the labels and convert to one-hot encoding\n",
    "labels = labels_df[\"gender\"].values\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(labels)\n",
    "labels = encoder.transform(labels)\n",
    "labels = to_categorical(labels, num_classes=2)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the input shape\n",
    "input_shape = (224, 224, 3)\n",
    "\n",
    "# Define the transformer model\n",
    "def transformer_model(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # Data augmentation\n",
    "    x = RandomFlip()(inputs)\n",
    "    x = RandomRotation(factor=0.2)(x)\n",
    "    x = RandomTranslation(height_factor=0.1, width_factor=0.1)(x)\n",
    "    x = RandomZoom(height_factor=0.2, width_factor=0.2)(x)\n",
    "    x = Rescaling(scale=1./255)(x)\n",
    "    \n",
    "    # Base model\n",
    "    base_model = EfficientNetB0(include_top=False, weights=\"imagenet\", input_tensor=x)\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(2, activation='softmax')(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create an instance of the transformer model\n",
    "model = transformer_model(input_shape)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.0001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_images, train_labels, epochs=10, batch_size=32, validation_data=(test_images, test_labels))\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(\"Test loss:\", test_loss)\n",
    "print(\"Test accuracy:\", test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81de5a98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58580a91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a881dc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b940fc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a67d21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
